"""
ì „ì²´ í•µì‹¬ í˜ì´ì§€ë¥¼ ë ˆì´ì•„ì›ƒ ê¸°ë°˜ìœ¼ë¡œ ì¶”ì¶œ
"""
import pdfplumber
from pathlib import Path
import json

def extract_page_with_layout(pdf, page_num):
    """ë‹¨ì¼ í˜ì´ì§€ë¥¼ ë ˆì´ì•„ì›ƒ ê¸°ë°˜ìœ¼ë¡œ ì¶”ì¶œ"""
    page = pdf.pages[page_num]
    
    # í˜ì´ì§€ í¬ê¸°
    width = page.width
    height = page.height
    
    # ì™¼ìª½/ì˜¤ë¥¸ìª½ ë¶„ë¦¬
    left_bbox = (0, 0, width/2, height)
    right_bbox = (width/2, 0, width, height)
    
    left = page.within_bbox(left_bbox)
    left_text = left.extract_text() or ""
    
    right = page.within_bbox(right_bbox)
    right_text = right.extract_text() or ""
    
    # í•©ì¹˜ê¸° (ì™¼ìª½ â†’ ì˜¤ë¥¸ìª½)
    combined = f"{left_text}\n\n{right_text}"
    
    return combined.strip()

def extract_all_core_pages():
    """ì „ì²´ í•µì‹¬ í˜ì´ì§€ ì¶”ì¶œ"""
    print("=" * 80)
    print("ğŸ“„ ë ˆì´ì•„ì›ƒ ê¸°ë°˜ ì „ì²´ í˜ì´ì§€ ì¶”ì¶œ")
    print("=" * 80)
    
    # í•µì‹¬ í˜ì´ì§€ (0-based)
    core_pages = [
        10, 11, 12, 13,  # ìì‚´ ì§•í›„ (p.11-14)
        17, 18, 19,      # ëŒ€ë©´ ë©´ë‹´ (p.18-20)
        23, 24, 25,      # ìœ„ê¸° ê°œì… (p.24-26)
        26, 27, 28, 29   # ìœ„í—˜ìš”ì¸ (p.27-30)
    ]
    
    results = {}
    
    with pdfplumber.open("data/manual.pdf") as pdf:
        for i, page_num in enumerate(core_pages, 1):
            print(f"\n[{i}/{len(core_pages)}] í˜ì´ì§€ {page_num + 1} ì¶”ì¶œ ì¤‘...")
            
            try:
                text = extract_page_with_layout(pdf, page_num)
                
                results[page_num + 1] = {
                    'text': text,
                    'length': len(text)
                }
                
                print(f"   âœ… {len(text)}ì ì¶”ì¶œ")
                
            except Exception as e:
                print(f"   âŒ ì‹¤íŒ¨: {e}")
                results[page_num + 1] = {
                    'text': '',
                    'length': 0,
                    'error': str(e)
                }
    
    # ì €ì¥
    print("\n" + "=" * 80)
    print("ğŸ’¾ ê²°ê³¼ ì €ì¥")
    print("=" * 80)
    
    output_dir = Path("data/layout_extracted")
    output_dir.mkdir(exist_ok=True)
    
    # JSON ì €ì¥
    with open(output_dir / "all_pages.json", "w", encoding="utf-8") as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    # ê°œë³„ txt ì €ì¥
    for page_num, data in results.items():
        with open(output_dir / f"page_{page_num:02d}.txt", "w", encoding="utf-8") as f:
            f.write(f"=== í˜ì´ì§€ {page_num} ===\n\n")
            f.write(data['text'])
    
    print(f"âœ… ì €ì¥ ì™„ë£Œ: {output_dir}/")
    
    # í†µê³„
    print("\n" + "=" * 80)
    print("ğŸ“Š í†µê³„")
    print("=" * 80)
    
    total_chars = sum(d['length'] for d in results.values())
    avg_chars = total_chars / len(results)
    
    print(f"\nì´ í˜ì´ì§€: {len(results)}ê°œ")
    print(f"ì´ ê¸€ììˆ˜: {total_chars:,}ì")
    print(f"í‰ê· : {avg_chars:.0f}ì/í˜ì´ì§€")
    
    print(f"\ní˜ì´ì§€ë³„ ê¸€ììˆ˜:")
    for page_num in sorted(results.keys()):
        length = results[page_num]['length']
        print(f"  p.{page_num}: {length:,}ì")
    
    return results

if __name__ == "__main__":
    results = extract_all_core_pages()
    
    print("\n" + "=" * 80)
    print("âœ¨ ì™„ë£Œ!")
    print("=" * 80)
    print("\në‹¤ìŒ ë‹¨ê³„:")
    print("  1. data/layout_extracted/ í´ë” í™•ì¸")
    print("  2. ëª‡ ê°œ í˜ì´ì§€ ë§¤ë‰´ì–¼ê³¼ ëŒ€ì¡°")
    print("  3. ë§Œì¡±ìŠ¤ëŸ¬ìš°ë©´ ì „ì²˜ë¦¬ ì§„í–‰")
    print("     â†’ python preprocessing/step2_preprocess.py")